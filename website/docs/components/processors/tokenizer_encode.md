---
title: tokenizer_encode
slug: tokenizer_encode
type: processor
status: experimental
categories: ["Services"]
---

<!--
     THIS FILE IS AUTOGENERATED!

     To make changes please edit the corresponding source file under internal/impl/<provider>.
-->

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

:::caution EXPERIMENTAL
This component is experimental and therefore subject to change or removal outside of major version releases.
:::
Tokenizes a string input based on a set of pre-defined text encodings.

```yml
# Config fields, showing default values
label: ""
tokenizer_encode:
  model_name: bert-base-uncase # No default (optional)
  config_file: config.json
  pretrained:
    tokenizer: "" # No default (required)
    add_prefix_space: false
    trim_offsets: true
```

## Fields

### `model_name`

The model name e.g., "bert-base-uncase" or path to directory contains model/config files.


Type: `string`  

```yml
# Examples

model_name: bert-base-uncase

model_name: /path/to/model/files

model_name: /path/to/config/files
```

### `config_file`

Config file name.


Type: `string`  
Default: `"config.json"`  

### `pretrained`

Loads a pretrained tokenizer.


Type: `object`  

### `pretrained.tokenizer`

Sets the pretrained tokenizer.


Type: `string`  
Options: `BertBaseUncased`, `BertLargeCasedWholeWordMaskingSquad`, `GPT2`, `RobertaBase`, `RobertaBaseSquad2`.

### `pretrained.add_prefix_space`

If enabled, adds a leading space to the first word, treating the leading word like any other in the sequence.


Type: `bool`  
Default: `false`  

### `pretrained.trim_offsets`

If enabled, trim offsets in the post-processing step to avoid including whitespaces.


Type: `bool`  
Default: `true`  


